---
title: "Waste Water Treatment"
description: |
  Waste water samples are divided into paired units and sent to separate laboratories for testing of the Biochemical Oxygen Demand and the amount of Suspended Solids. This is done to make sure that the measurements which guide the activities of the treatment plant are accurate and consistent. The Hotelling T2 test is used to make the comparison across the two dependent variables with the State/Commercial laboratory serving as the grouping variable.
categories:
  - Hotelling T2
  - One sample
  - Paired Units
author:
  - name: Gavin Gordon
    url: https://example.com/norajones
date: 12-16-2020
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
#Set some global options for the output
knitr::opts_chunk$set(echo = F,cache = T,message = F,warning = F,results='asis')
```

```{r}
#Read in the packages 
library(data.table)
library(readr)
library(tidyverse)
library(plotly)
library(gt)
library(kableExtra)
library(knitr)
library(fitdistrplus)
library(heplots)
library(pander)
library(gtsummary)
library(rrcov)
library(emmeans)
library(expss)
library(xtable)
```

```{r}
#Read in the data
datafile <- read_csv("C:/Users/gavin/Desktop/PairedComparisons/Hotelling/waterQuality/waterquality.csv")

#Calculate the differences for pairs
datafile <- datafile %>% mutate(diffbod = combod - statebod,diffss = comss - statess)

```

# Problem
Municipal waste water treatment plants are required by law to monitor their discharges into rivers and streams on a regular basis. Concern about the reliability of data from one of these self-monitoring programs led to a study in which samples of effluent were divided and sent to two laboratories for testing. One-half of each sample was sent to the Wisconsin State Laboratory of Hygiene, and one-half was sent to a private commercial laboratory routinely used in the monitoring program. Measurements of biochemical oxygen demand (BOD) and suspended solids (SS) were obtained, for n = 11 sample splits, from the two laboratories.  

This problem will be approached using the paired Hotelling T2 test.

**Note**: This problem was taken from Johnson 1992, example 6.1. I have added the exploration of assumptions in the replication of the results.   
&nbsp;
&nbsp;
&nbsp;
&nbsp;
  
      



```{r}
#Compute the summary table for the differences
datafile %>% 
  apply_labels(diffbod = "BOD",diffss = "SS") %>%
  dplyr::select(diffbod,diffss) %>% 
  tbl_summary(
              type = all_continuous() ~ "continuous2",
              statistic = all_continuous() ~ c("{mean} ({sd})", 
                                               "{median} ({p25},{p75})",
                                               "{min}, {max}"),
              missing = "no") %>% 
  as_gt() %>%
  tab_header(
    title = "Summary Statistics",
    subtitle = "for differences"
  ) 

  
```
&nbsp;
&nbsp;
&nbsp;
&nbsp;

## Check for Assumptions
1. **Outliers and Group level Normality**


```{r fig.cap="Normal Distribution plots for BOD",fig.pos='H',fig.align='center'}

#Compute distribution checking plots for the variable of interest
norm <- datafile %>%  dplyr::select(diffbod) 
norm <- fitdist(as.vector(norm$diffbod), distr = "norm")
par(mfrow = c(2, 2),mar = c(2,2,1.75,1.75))
 denscomp(list(norm))
 qqcomp(list(norm))
  cdfcomp(list(norm))
  ppcomp(list(norm))
```

The histogram for the BOD differences is skewed with most of the data falling in the negative number range (median equals -14 as well). The points seem to oscillate about the QQ, PP and cumulative distribution plots but seem to hug the lines; this is not ideal but can occur especially with small sample sizes. The plot behaviors show promising approximations to normality. There does not seem to be any alarming data points for consideration as outliers.  

&nbsp;
&nbsp;
&nbsp;
&nbsp;


```{r fig.cap="Normal Distribution plots for SS",fig.pos='H',fig.align='center'}
norm <- datafile %>%  dplyr::select(diffss) 
norm <- fitdist(as.vector(norm$diffss), distr = "norm")
par(mfrow = c(2, 2),mar = c(2,2,1.75,1.75))
 denscomp(list(norm))
 qqcomp(list(norm))
  cdfcomp(list(norm))
  ppcomp(list(norm))
```
The SS variable does not follow a normal distribution. There are two data points which have differences that are quite alarming relative to the other data points. This is most clearly shown in the histogram where these two values occur above the value of 40. It is likely that these two points will distort the normality assumption; also they present the idea that there may be a subgroup within the dataset that needs to be taken into account. None of the distribution curves seem to match well with the data.  

&nbsp;
&nbsp;
&nbsp;
&nbsp;


<center>

```{r fig.align = 'center'}
#Plot for the bivariate density
ggplotly(ggplot(data = datafile ,aes(x = diffbod,y = diffss))  + stat_density2d(aes(fill = ..level..), geom = "polygon") + 
  theme_bw() +
  labs(x = "BOD", y = "SS",title = "Bivariate Density plot for BOD and SS") + 
  theme(plot.title = element_text(hjust = 0.5),
        axis.title.x = element_text(size =14),
        axis.title.y = element_text(size =14),
        legend.text = element_text(size = 12),
        
        legend.title = element_text(size = 12)) 
  
)

```
</center>
The bivariate normal distribution seems to be bimodal which adds more evidence to the idea that there may be a subgroup present within the data. Overall the normality assumption is not to a satisfactory level when all of the data is included.  

&nbsp;
&nbsp;
&nbsp;
&nbsp;

### Outlier Removal

```{r fig.cap="Normal Distribution plots for SS with outliers removed",fig.pos='H',fig.align='center'}
norm <- datafile  %>% filter(diffss < 40) %>%  dplyr::select(diffbod)
norm <- fitdist(as.vector(norm$diffbod), distr = "norm")
par(mfrow = c(2, 2),mar = c(2,2,1.75,1.75))
 denscomp(list(norm))
 qqcomp(list(norm))
  cdfcomp(list(norm))
  ppcomp(list(norm))
```
When the two outliers are removed, the BOD variable shows even more acceptable behavior with respect to normality.  

&nbsp;
&nbsp;
&nbsp;
&nbsp;


```{r fig.cap="Distribution Plots for Commerical Lab BOD Variable",fig.pos='H',fig.align='center'}
norm <- datafile  %>% filter(diffss < 40) %>%  dplyr::select(diffss)
norm <- fitdist(as.vector(norm$diffss), distr = "norm")
par(mfrow = c(2, 2),mar = c(2,2,1.75,1.75))
 denscomp(list(norm))
 qqcomp(list(norm))
  cdfcomp(list(norm))
  ppcomp(list(norm))
```
With the removal of the two outliers another problem surfaces with the SS variable. It would seem that there is another grouping of the data points such that four are positive while five are negative. It is unlikely that any meaningful information can be derived with respect to this variable; an investigation targeting this variable should be undertaken. The bivariate contour plot seems to have lost it's interpretability for this data.     


&nbsp;
&nbsp;
&nbsp;
&nbsp;




2. **Sub-populations within the vector means**: Details on the methodology of the experiment were not given to affirm the randomization of the experimental units when being sent to the commercial/state laboratory although this can be assumed given the nature/sensitivity of the problem. There are no other variables available to conduct subgroup analysis to confirm/reject the idea that there are other factors that contribute to the outcome of the experiment. There does seem to be evidence that indicates a sub-population is present thus this assumption is considered to be violated.  
3. **Independence of the paired experimental units**: the problem description suggests that samples were taken and then each was split to produce the pair. We will assume that the samples were taken independently of each other with the dependence being formed by the split.  


If this technique were to used under these conditions the results should be taken with caution; there should be an investigation into the bimodal nature of the distribution. The analysis will proceed for illustrative purposes.  

&nbsp;
&nbsp;
&nbsp;
&nbsp;


## Data Analysis

<center>

```{r fig.align='center',fig.cap="A",fig.subcap=c("v","d")}
#Compute the Hotelling T2 stat
testdata <- data.frame(datafile[,c(6,7)])
t2 <- T2.test(testdata)


#Build the output table for the Hotelling T2 test
results <- round(data.table(t2$statistic[1],t2$statistic[2],t2$p.value),2)
names(results) <- c("T2 Stat","F value", "P value")

results %>% kable(align = 'clc', caption = 'Hotelling Output',format = "html", table.attr = "style='width:40%;'") %>%
    kable_styling(position = "float_left")


#Compute the simultaneous confidence intervals
upperbod  <- mean(datafile$diffbod) + sqrt((10*2)/(9) * qf(.95,2,9))*sqrt(var(datafile$diffbod)/11)  

lowerbod <- mean(datafile$diffbod) - sqrt((10*2)/(9) * qf(.95,2,9))*sqrt(var(datafile$diffbod)/11)  

upperss  <- mean(datafile$diffss) + sqrt((10*2)/(9) * qf(.95,2,9))*sqrt(var(datafile$diffss)/11)  

lowerss  <- mean(datafile$diffss) - sqrt((10*2)/(9) * qf(.95,2,9))*sqrt(var(datafile$diffss)/11) 


# Build the confidence interval table
confint <- data.frame(Variable = c("BOD","SS"),Lower = round(c(lowerbod,lowerss),2),Upper = round(c(upperbod,upperss),2))

confint %>% kable("html", align = 'clc', caption = 'Confidence Intervals', table.attr = "style='width:40%;'") %>%
    kable_styling(position = "left")


```

</center>

So as you might have noticed we have a rather peculiar situation. The test statistic p value would suggest that the means of BOD and SS are significantly different from zero. However the confidence intervals include zero which usually indicate that, since zero is a possibility then you may not assume a difference. The explanation given states that the confidence intervals are constructed around a value which is represented as a linear combination of the differences in BOD and SS; for all of the possible linear combinations only two result in intervals that contain zero being the (1,0) and (0,1) pairs. All other linear combinations do not contain zero.  

The interpretation that will be adopted is that there seems to be a difference in the results from the two labs given that most of the data from the BOD variable is highly skewed in one direction that is below the zero margin.  

&nbsp;  
&nbsp;  
&nbsp;  


## References
Johnson, R. A., & Wichern, D. W. (1992). Applied multivariate statistical analysis. Englewood Cliffs, N.J: Prentice Hall