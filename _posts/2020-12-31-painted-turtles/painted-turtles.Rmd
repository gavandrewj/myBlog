---
title: "Painted Turtles"
description: |
  An application of the Hotelling T2 test where the measurements of the carapaces of painted turtles are compared across sex. Shows a visualization of the utility that accounting for several variables under one technique can have.

base_url: https://github.com/gavandrewj/myBlog/

categories:
  - Hotelling T2
  - Independent Samples 
  
author:
  - name: Gavin Gordon
    url: https://example.com/norajones
date: 12-31-2020
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,cache = T,message = F,warning = F)
```

```{r}
library(tidyverse)
library(fitdistrplus)
library(SHT)
library(vroom)
library(plotly)
library(gt)
library(gtsummary)
library(Hotelling)
library(pander)
library(expss)
library(beanplot)
library(pairwiseCI)
library(heplots)
```
# Problem (Question 6.18)
This problem is taken from **Johnson 1992**. Measurements on the carapaces from a study of  painted turtles are given. The aim is to determine whether or not there are differences across the sex. 

```{r}
#Importing data
data <- vroom("C:/Users/gavin/Documents/GitHub/blogdata/paintedturtle.csv")
data$sex <- factor(data$sex)
data$loglength <- log(data$length)
data$logwidth <- log(data$width)
data$logheight <- log(data$height)
```




```{r}
data %>% 
  select(length,width,height,sex) %>%
  apply_labels(length= "Length",width = "Width",height = "Height") %>% 
  tbl_summary(by = sex,
              type = all_continuous() ~ "continuous2",
              statistic = all_continuous() ~ c("{mean} ({sd})", 
                                               "{median} ({p25},{p75})",
                                               "{min}, {max}"),
              missing = "no") %>% 
  as_gt() %>%
  tab_header(
    title = "Summary Statistics",
    subtitle = "across Sex"
  ) 

```
Most of the analysis will be done on the Logarithm scale.

## A Visualization of the Problem
### Univariate Plots
The first three graphs will look at the problem from a univariate perspective. The particular graph that was chosen (beanplot) to represent the information allows for comment on the distribution features so this will be done at the same time.

```{r fig.cap= "Distributions of Length over Sex",fig.align='center'}
 beanplot(loglength ~ sex,data = data,col = "lightblue") 
  
```
 We can see that Females have one major and one minor mode with the presence of a potential outlier that is roughly 5.2. The Males seem to have one mode, with a distribution that is eerily symmetric. The median for the Females as well as most of it's data points fall above this the grand average (dotted line) with the opposite occurring for the Males.  
 The reason why there seems to be a minor mode should be inspected as perhaps there is a subgroup present within the dataset that should be accounted for. Given the information thus far it would not be surprising to know that the univariate *welch t-test* reports a difference in the two sexes over the feature of length. Most of the overlap between the two distributions seem to happen with the 75% quantile of the males and the lower 25% quantile of the females. 
 
 
 
 
```{r fig.cap= "Distributions of Width over Sex",fig.align='center'}
 beanplot(logwidth ~ sex,data = data,col = "lightgreen") 
  
```
We can see that the densities both have a single mode. There seems to be a similar sort of overlap between the sample points as with the feature length. It is the case that the univariate *welch t test* reports a difference in width between the two sexes. There is a potential outlier in the male distribution but overall there isn't any alarming feature.
 
```{r fig.cap= "Distributions of Height over Sex",fig.align='center'}
 beanplot(logheight ~ sex,data = data,col = "lightyellow") 
  
```
Most of what was already discussed applies to describing the above plot. Both are considered to have single modes. Even though there is somewhat of a distortion in the upper percentiles for the female, there are not enough data points developing that mode to indicate a potential subgroup; this is probability better explained by a higher level of variation in the population. 


### Bivariate Plots
Now we will try to see what value adding another variable can bring to the analysis.

```{r}
ggplotly(ggplot(data,aes(x = loglength,y = logwidth,color = sex)) + 
  geom_point() + 
  theme_bw() + 
  labs(x = "Width",y = "Length",title = "Length vs Width Difference") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  stat_ellipse()  
)
```
We are concerned about the overlap between the distributions for the univariate plots. In some cases the variation may be enough to cloud any difference that may actually exist. Ideally the addition of another variable, in this case Width to the plot of length gives another dimension to essentially separate the data points and allows us to compute the mean in a more accurate manner. From the above plot this does not seem to be the case; the overlap in the upper and lower percentiles as mentioned before, is now visualized better.   

```{r}
ggplotly(ggplot(data,aes(x = loglength,y = logheight,color = sex)) + 
  geom_point() + 
  theme_bw() + 
  labs(x = "Length",y = "Height",title = "Length vs Height Difference") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
    stat_ellipse()
)
```
The plot of length against height brings us closer to what we hope to achieve. In the lower ranges, from the univariate perspective those points are intertwined with each other; however the addition of the Height feature to length has highlighted the difference in the two sexes as there is now some distance between the colored points. This is not perfect but it will make the estimates more accurate. 

```{r}
ggplotly(ggplot(data,aes(x = logheight,y = logwidth,color = sex)) + 
  geom_point() + 
  theme_bw() + 
  labs(x = "Height",y = "Width",title = "Width vs Height Difference") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
    stat_ellipse()
)
```

A similar case to the previous plot is observed where there is some separation when Height is combined with Width. It would seem that the Height variable adds valuable discriminatory power to the analysis.

&nbsp;

```{r}
plot_ly(data = data, x = data$loglength,y = data$logwidth,z = data$logheight,color = data$sex) %>% layout(title = "Plot of All Dependent Variables",
                scene = list(
                  xaxis = list(title = "Length"),
                  yaxis = list(title = "Width"),
                  zaxis = list(title = "Height")
                  )
                )

```

Finally we examine the 3D plot of the dependent variables. This requires you to interact with the graph presented. If you were to move the chart such that you were looking down with the length and width features in the typically x and y plane then you would replicate the first chart where the separation power is not ideal. Now you should rotate the chart such that the height feature comes into focus, as you rotate it then you might notice how the feature lifts some of the green points (females) out of the cloud of blue points (males). Although you can ask for this "lifting effect" to be greater, nevertheless it speaks to the limitations of univariate cases and what can be accomplished by accounting for more variables in the same analysis technique.

## Assumptions

1. **Independence of Observations**  

The observations are taken from different turtles.

2. **Normality and Outliers**  

The sample sizes within the Group Sex would be enough to be considered a large sample thus the Central Limit theorem would take effect to assure normality of the sample mean. Also, the previous plots show that there are likely no point that severely disturb the overall trend that is displayed within Sex across the combination of variables.  



3. **Equality of Variance**

<center>

```{r,fig.align='center'}
pander(boxM(cbind(logwidth,logheight,loglength) ~ sex,data = data),caption = "Box's M-test for Homogeneity of Covariance Matrices")

```

</center>

The test shows that the variables do not have the same variance across the groups. Although this assumption was aided by the use of the logarithm transformation, the overall problem was not reduced to satisfactory level.  
Since we do not have equality of variances, we now consider a similar technique that does not require this assumption. It falls into the same problem category as the *Welch's t test* known as the *Behrens–Fisher* type problems. 

&nbsp;  
  

## Analysis

<center>

```{r}
#options(scipen=999)
males <- as.matrix(subset(data,sex == "Male")[,5:7])
females <- as.matrix(subset(data ,sex == "Female")[,5:7])
pander(mean2.2004KY(males,females),caption = "Two-sample Test for Multivariate Means",digits = 6)

```
</center>

&nbsp;  
This analysis uses the technique established in **Krishnamoorthy 2004**.

The p value attempts to quantify how often we may come across such a dataset given that the null hypothesis is true. If we were to assume that there is no difference between the Sex across the variables of Length, Width and Height then the data that was collected would be considered to be an extremely rare event. Therefore, this should serve as evidence that there is a difference between the Sexes along one or more of the variables considered until some other explanation arises that may state otherwise.

&nbsp;  

### Confidence Intervals for each Variable

The original question asked for the calculation of both simultaneous and bonferroni intervals. Since we are not assuming equality of variances, I am unsure as to whether simultaneous confidence intervals can be constructed. Thus only the bonferroni intervals are constructed. 


<center>

```{r}

length <- pairwiseCI(data = data , length ~ sex, conf.level = 0.95/6)
width <- pairwiseCI(data = data , width ~ sex, conf.level = 0.95/6)
height <- pairwiseCI(data = data , height ~ sex, conf.level = 0.95/6)

intervals <- data.frame(Variable = c("Length","Width","Height"), Estimate = round(c(length$byout[[1]]$estimate,width$byout[[1]]$estimate,height$byout[[1]]$estimate),2),Lower = round(c( length$byout[[1]]$lower,width$byout[[1]]$lower,height$byout[[1]]$lower),2),Upper = round(c(length$byout[[1]]$upper,width$byout[[1]]$upper,height$byout[[1]]$upper),2))

pander(intervals,caption = "Bonferonni Confidence Intervals for Features")

```

</center>

&nbsp;  
&nbsp; 

## References

Johnson, R. A., & Wichern, D. W. (1992). Applied multivariate statistical analysis. Englewood Cliffs, N.J: Prentice Hall  

Krishnamoorthy, K., & Yu, J. (2004). Modified Nel and Van der Merwe test for the multivariate Behrens–Fisher problem. Statistics & probability letters, 66(2), 161-169.

NCSS Hotelling’S Twosample T2. [pdf] Available at: <https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Hotellings_Two-Sample_T2.pdf> 
