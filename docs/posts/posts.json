[
  {
    "path": "posts/2021-10-25-monte-carlo-power-analysis-independent-two-sample-difference-of-means/",
    "title": "Monte Carlo Power Analysis: Independent Two Sample Difference of Means",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Gavin Gordon",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2021-10-25",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\nMotivation\r\nAt some point you may think, “boy this is overkill”. But that’s not really fair to say if you’ve ever went in search of a power analysis for a multinomial multiple logistic regression and had to report recommendations from the literature to a client instead of some hard numbers. I still haven’t found any software for it (you know the free kind) although there is that one stack exchange post that hints at what you could do.\r\nI found it daunting that something like that wasn’t readily accessible/available in the same vein as one could locate and utilize a linear regression. Eventually I started to grasp why it might be difficult to distill the complexity of a dataset to a few much less one formula for a sample size.\r\nThis led me to favor simulations. Okay everything in stats is a simulation but that itself wasn’t evident to me for quite some time. The idea that the key to unlocking an extremely versatile method for power analysis is already available the moment one is introduced to any particular test, had you the code. I feel cheated that something like this isn’t introduced in alongside content of lets say from third year.\r\nSo the motivation is that this is a proof of concept, that one could extend to any (I hope) kind of modeling exercise you could undertake for determining sample sizes/power (or the equivalent in the bayesian language). I imagine as the more complex modeling gets such as with hierarchical models, simulations become inevitable so this is also me setting the ground work. This also forces you to become intimate with what you expect from your data, to what analysis you can consider, to dealing with things such as cost analysis, interim analysis (such as for clinical trials which I hope to make a general use case of), expectation of missing data, and so on.\r\nIntuition behind the technique\r\nBasically you create datasets for what you think your data is likely to look like, and run the analysis you expect to run. This gives another purpose to going through the grind of a literature review in detail to get an idea for what other persons who investigated what you’re doing would have found; such knowledge helps shape your expectation.\r\nYou simulate thousands of datasets (easier than it sounds) and check to see whether a particular sample size will capture an effect you’re interested in or you think exists. There are a few critera that I look at such that this exercise may look a bit different from what you might have come across in your own work.\r\nIn this case we may try to detect a standardized difference in means of 0.8 for which we would at a few criteria before selecting a sample size.\r\nThe data will be generated from distributions using parameters. Have we managed to recover the parameters. This I check for all the parameters not just the mean but also the variance in the case of the normal distribution. This becomes important when you have unequal variances between the groups.\r\nIs the length of the credible/confidence interval small enough? This is something I would discuss with a client. How much precision around the estimate would have to be before the estimate becomes action worthy?\r\nIs worth considering an unequal treatment/sampling allocation (something other than a 1:1 ratio)?\r\nSatisfying these two criteria seems like it would take care of other considerations such as whether the value of zero is in the credible/confidence interval, or keeping a direct count of how many times a test reaches significance.\r\nOn to the Simulations\r\nProblem One\r\nThe first problem we will consider is to determine a sample size with a power of 0.8 for a test for a standardized difference in means of 2.5 magnitude. The variance between the two groups will be the same with a one to one group allocation.\r\n\\[\r\n\\mu_1 \\sim N(2,1) \r\n\\]\r\n\\[\r\n\\mu_2 \\sim N(2.8,1)\r\n\\]\r\n\\[\r\ne \\sim N(0,1)\r\n\\]\r\n\\[\r\n\\dfrac{\\Delta}{\\sigma} = \\dfrac{\\mu_2 - \\mu_1}{\\sigma} = \\dfrac{2.8-2}{1} = 0.8\r\n\\]\r\n\r\n\r\n\r\nThe above animation should give an easy enough idealization of our expected data. Now that we have the datasets, this is easy as passing each through a regression problem for which I use the brms package in R utilzing the defaults for bayesian estimation.\r\nFor each iteration of the regression certain information is extracted namely, the parameter means, 97.5 and 2.75 quantiles of the parameter distributions.\r\nFor these problems I make use of the ability to explicity model the variances instead of using a pooled estimate of some kind. Even though I know that the variances are the same this will become set the trend for the upcoming problem.\r\nAn example of the model output is as such:\r\n\r\n\r\nregress <-  readRDS(\"C:/Users/gavin/Documents/GitHub/myBlog/regression_sample_p1.rds\")\r\n\r\ntab_model(regress)\r\n\r\n\r\n\r\n \r\n\r\n\r\ny\r\n\r\n\r\nPredictors\r\n\r\n\r\nEstimates\r\n\r\n\r\nCI (95%)\r\n\r\n\r\nIntercept\r\n\r\n\r\n2.08\r\n\r\n\r\n1.42 – 2.73\r\n\r\n\r\nsigma_Intercept\r\n\r\n\r\n-0.05\r\n\r\n\r\n-0.46 – 0.53\r\n\r\n\r\nxgrouptwo\r\n\r\n\r\n0.96\r\n\r\n\r\n0.10 – 1.82\r\n\r\n\r\nsigma_xgrouptwo\r\n\r\n\r\n-0.13\r\n\r\n\r\n-0.85 – 0.56\r\n\r\n\r\nObservations\r\n\r\n\r\n20\r\n\r\n\r\nR2 Bayes\r\n\r\n\r\n0.256\r\n\r\n\r\nwhere the variances are given on a log scale but is better views as such.\r\n\r\n\r\nhyp <- c(\"exp(sigma_Intercept) = 0\",\r\n         \"exp(sigma_Intercept + sigma_xgrouptwo) = 0\")\r\n(hyp <- hypothesis(regress, hyp))\r\n\r\n\r\nHypothesis Tests for class b:\r\n                Hypothesis Estimate Est.Error CI.Lower CI.Upper\r\n1 (exp(sigma_Interc... = 0     1.00      0.27     0.63     1.69\r\n2 (exp(sigma_Interc... = 0     0.87      0.24     0.55     1.47\r\n  Evid.Ratio Post.Prob Star\r\n1         NA        NA    *\r\n2         NA        NA    *\r\n---\r\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\r\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\r\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\r\nPosterior probabilities of point hypotheses assume equal prior probabilities.\r\n\r\nplot(hyp)\r\n\r\n\r\n\r\n\r\nThe relevant information is extracted and then the entire process is repeated for another sample size. The first useful piece of information is that for the estimated difference in the means. This effect size is considered large and so it doesn’t require a large sample provided that you are on point with your modeling assumptions, to fit an adquate model describing this situation.\r\n\r\n\r\n{\"x\":{\"data\":[{\"x\":[8.5,8.5,41.5,41.5],\"y\":[null,null,null,null],\"text\":\"yintercept: NA\",\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(255,255,255,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[10,15,20,25,30,35,40],\"y\":[2.681,2.462,2.397,2.47,2.397,2.385,2.652],\"text\":[\"samplesize: 10<br />xgrouptwo: 2.681<br />allocation: red<br />xgrouptwo_q2.5: 1.074<br />xgrouptwo_q97.5: 4.286<br />interval length:  3.212 <\\/br>interval length criteria satisfied:  0 <\\/br>detect probability:  1\",\"samplesize: 15<br />xgrouptwo: 2.462<br />allocation: red<br />xgrouptwo_q2.5: 1.199<br />xgrouptwo_q97.5: 3.723<br />interval length:  2.524 <\\/br>interval length criteria satisfied:  0 <\\/br>detect probability:  1\",\"samplesize: 20<br />xgrouptwo: 2.397<br />allocation: red<br />xgrouptwo_q2.5: 1.313<br />xgrouptwo_q97.5: 3.485<br />interval length:  2.172 <\\/br>interval length criteria satisfied:  0 <\\/br>detect probability:  1\",\"samplesize: 25<br />xgrouptwo: 2.470<br />allocation: red<br />xgrouptwo_q2.5: 1.614<br />xgrouptwo_q97.5: 3.333<br />interval length:  1.719 <\\/br>interval length criteria satisfied:  0 <\\/br>detect probability:  1\",\"samplesize: 30<br />xgrouptwo: 2.397<br />allocation: red<br />xgrouptwo_q2.5: 1.642<br />xgrouptwo_q97.5: 3.155<br />interval length:  1.513 <\\/br>interval length criteria satisfied:  0 <\\/br>detect probability:  1\",\"samplesize: 35<br />xgrouptwo: 2.385<br />allocation: red<br />xgrouptwo_q2.5: 1.728<br />xgrouptwo_q97.5: 3.037<br />interval length:  1.309 <\\/br>interval length criteria satisfied:  0 <\\/br>detect probability:  0.8\",\"samplesize: 40<br />xgrouptwo: 2.652<br />allocation: red<br />xgrouptwo_q2.5: 1.996<br />xgrouptwo_q97.5: 3.310<br />interval length:  1.314 <\\/br>interval length criteria satisfied:  0 <\\/br>detect probability:  1\"],\"type\":\"scatter\",\"mode\":\"lines+markers\",\"opacity\":1,\"line\":{\"color\":\"transparent\"},\"error_y\":{\"array\":[1.605,1.261,1.088,0.863,0.758,0.652,0.658],\"arrayminus\":[1.607,1.263,1.084,0.856,0.755,0.657,0.656],\"type\":\"data\",\"width\":0,\"symmetric\":false,\"color\":\"rgba(255,0,0,1)\"},\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(255,0,0,1)\",\"opacity\":1,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(255,0,0,1)\"}},\"hoveron\":\"points\",\"frame\":null},{\"x\":[8.5,41.5],\"y\":[2.5,2.5],\"text\":\"yintercept: 2.5\",\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,0,0,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":45.4063926940639,\"r\":7.30593607305936,\"b\":41.8264840182648,\"l\":31.4155251141553},\"plot_bgcolor\":\"rgba(255,255,255,1)\",\"paper_bgcolor\":\"rgba(255,255,255,1)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"title\":{\"text\":\"Properties for Main Effect across Sample Sizes\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":17.5342465753425},\"x\":0.5,\"xref\":\"paper\"},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[8.5,41.5],\"tickmode\":\"array\",\"ticktext\":[\"10\",\"20\",\"30\",\"40\"],\"tickvals\":[10,20,30,40],\"categoryorder\":\"array\",\"categoryarray\":[\"10\",\"20\",\"30\",\"40\"],\"nticks\":null,\"ticks\":\"outside\",\"tickcolor\":\"rgba(51,51,51,1)\",\"ticklen\":3.65296803652968,\"tickwidth\":0.66417600664176,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(235,235,235,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"Sample Size (Total)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[0.3634,4.9966],\"tickmode\":\"array\",\"ticktext\":[\"1\",\"2\",\"3\",\"4\"],\"tickvals\":[1,2,3,4],\"categoryorder\":\"array\",\"categoryarray\":[\"1\",\"2\",\"3\",\"4\"],\"nticks\":null,\"ticks\":\"outside\",\"tickcolor\":\"rgba(51,51,51,1)\",\"ticklen\":3.65296803652968,\"tickwidth\":0.66417600664176,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(235,235,235,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"Location Effect Size\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":\"transparent\",\"line\":{\"color\":\"rgba(51,51,51,1)\",\"width\":0.66417600664176,\"linetype\":\"solid\"},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false,\"legend\":{\"bgcolor\":\"rgba(255,255,255,1)\",\"bordercolor\":\"transparent\",\"borderwidth\":1.88976377952756,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895}},\"hovermode\":\"x\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"460824f57615\":{\"yintercept\":{},\"type\":\"scatter\"},\"460878936cd9\":{\"x\":{},\"y\":{},\"colour\":{},\"ymin\":{},\"ymax\":{},\"text\":{}},\"460868664863\":{\"x\":{},\"y\":{},\"colour\":{},\"ymin\":{},\"ymax\":{},\"text\":{}},\"46081aa860b6\":{\"yintercept\":{}}},\"cur_data\":\"460824f57615\",\"visdat\":{\"460824f57615\":[\"function (y) \",\"x\"],\"460878936cd9\":[\"function (y) \",\"x\"],\"460868664863\":[\"function (y) \",\"x\"],\"46081aa860b6\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\r\nBy hovering over a particular point we have access to more information about that particular sample size.\r\nThe next informative parameter is that of either of the variances. It is important that this is captured well as this will decide whether your data is too noisy to even begin to interpret what you gathered.\r\n\r\n\r\n{\"x\":{\"data\":[{\"x\":[8.5,41.5,null,8.5,41.5],\"y\":[0,0,null,0.5,0.5],\"text\":[\"yintercept: 0.0\",\"yintercept: 0.0\",null,\"yintercept: 0.5\",\"yintercept: 0.5\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(255,255,255,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[10,15,20,25,30,35,40],\"y\":[1.204,1.051,1.069,0.899,0.999,1.023,1.034],\"text\":[\"samplesize: 10<br />sigma_xgrouptwo: 1.204<br />allocation: red<br />sigma_xgrouptwo_q2.5: 0.456<br />sigma_xgrouptwo_q97.5: 4.284<br />interval length:  3.828 <\\/br>interval length criteria satisfied:  0 <\\/br>detect probability:  1\",\"samplesize: 15<br />sigma_xgrouptwo: 1.051<br />allocation: red<br />sigma_xgrouptwo_q2.5: 0.416<br />sigma_xgrouptwo_q97.5: 2.046<br />interval length:  1.63 <\\/br>interval length criteria satisfied:  0 <\\/br>detect probability:  1\",\"samplesize: 20<br />sigma_xgrouptwo: 1.069<br />allocation: red<br />sigma_xgrouptwo_q2.5: 0.454<br />sigma_xgrouptwo_q97.5: 1.807<br />interval length:  1.353 <\\/br>interval length criteria satisfied:  0.1 <\\/br>detect probability:  1\",\"samplesize: 25<br />sigma_xgrouptwo: 0.899<br />allocation: red<br />sigma_xgrouptwo_q2.5: 0.476<br />sigma_xgrouptwo_q97.5: 1.656<br />interval length:  1.18 <\\/br>interval length criteria satisfied:  0.4 <\\/br>detect probability:  1\",\"samplesize: 30<br />sigma_xgrouptwo: 0.999<br />allocation: red<br />sigma_xgrouptwo_q2.5: 0.600<br />sigma_xgrouptwo_q97.5: 1.775<br />interval length:  1.175 <\\/br>interval length criteria satisfied:  0.4 <\\/br>detect probability:  1\",\"samplesize: 35<br />sigma_xgrouptwo: 1.023<br />allocation: red<br />sigma_xgrouptwo_q2.5: 0.756<br />sigma_xgrouptwo_q97.5: 2.035<br />interval length:  1.279 <\\/br>interval length criteria satisfied:  0.4 <\\/br>detect probability:  0.8\",\"samplesize: 40<br />sigma_xgrouptwo: 1.034<br />allocation: red<br />sigma_xgrouptwo_q2.5: 0.650<br />sigma_xgrouptwo_q97.5: 1.643<br />interval length:  0.993 <\\/br>interval length criteria satisfied:  0.7 <\\/br>detect probability:  1\"],\"type\":\"scatter\",\"mode\":\"lines+markers\",\"opacity\":1,\"line\":{\"color\":\"transparent\"},\"error_y\":{\"array\":[3.08,0.995,0.738,0.757,0.776,1.012,0.609],\"arrayminus\":[0.748,0.635,0.615,0.423,0.399,0.267,0.384],\"type\":\"data\",\"width\":0,\"symmetric\":false,\"color\":\"rgba(255,0,0,1)\"},\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(255,0,0,1)\",\"opacity\":1,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(255,0,0,1)\"}},\"hoveron\":\"points\",\"frame\":null},{\"x\":[8.5,41.5],\"y\":[1,1],\"text\":\"yintercept: 1\",\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,0,0,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":45.4063926940639,\"r\":7.30593607305936,\"b\":41.8264840182648,\"l\":31.4155251141553},\"plot_bgcolor\":\"rgba(255,255,255,1)\",\"paper_bgcolor\":\"rgba(255,255,255,1)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"title\":{\"text\":\"Properties for Scale Effect for Group Two across Sample Sizes\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":17.5342465753425},\"x\":0.5,\"xref\":\"paper\"},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[8.5,41.5],\"tickmode\":\"array\",\"ticktext\":[\"10\",\"20\",\"30\",\"40\"],\"tickvals\":[10,20,30,40],\"categoryorder\":\"array\",\"categoryarray\":[\"10\",\"20\",\"30\",\"40\"],\"nticks\":null,\"ticks\":\"outside\",\"tickcolor\":\"rgba(51,51,51,1)\",\"ticklen\":3.65296803652968,\"tickwidth\":0.66417600664176,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(235,235,235,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"Sample Size (Total)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-0.3274,5.0274],\"tickmode\":\"array\",\"ticktext\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"],\"tickvals\":[0,1,2,3,4,5],\"categoryorder\":\"array\",\"categoryarray\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"],\"nticks\":null,\"ticks\":\"outside\",\"tickcolor\":\"rgba(51,51,51,1)\",\"ticklen\":3.65296803652968,\"tickwidth\":0.66417600664176,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(235,235,235,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"Scale Effect Size\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":\"transparent\",\"line\":{\"color\":\"rgba(51,51,51,1)\",\"width\":0.66417600664176,\"linetype\":\"solid\"},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false,\"legend\":{\"bgcolor\":\"rgba(255,255,255,1)\",\"bordercolor\":\"transparent\",\"borderwidth\":1.88976377952756,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895}},\"hovermode\":\"x\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"4608647a170f\":{\"yintercept\":{},\"type\":\"scatter\"},\"460872f72151\":{\"x\":{},\"y\":{},\"colour\":{},\"ymin\":{},\"ymax\":{},\"text\":{}},\"460849dc3f34\":{\"x\":{},\"y\":{},\"colour\":{},\"ymin\":{},\"ymax\":{},\"text\":{}},\"460816ed2f5\":{\"yintercept\":{}}},\"cur_data\":\"4608647a170f\",\"visdat\":{\"4608647a170f\":[\"function (y) \",\"x\"],\"460872f72151\":[\"function (y) \",\"x\"],\"460849dc3f34\":[\"function (y) \",\"x\"],\"460816ed2f5\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\r\nWe see the same criteria as mentioned for the location effect size.\r\nProblem Two\r\nNow we will consider a problem that deals with a smaller location effect size as well as with the additional complication of unequal variances.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-10-25-monte-carlo-power-analysis-independent-two-sample-difference-of-means/monte-carlo-power-analysis-independent-two-sample-difference-of-means_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2021-10-25T22:07:10-04:00",
    "input_file": "monte-carlo-power-analysis-independent-two-sample-difference-of-means.knit.md"
  },
  {
    "path": "posts/2021-10-24-wilcoxin-mann-whitney-test/",
    "title": "Wilcoxin Mann-Whitney Test",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Gavin Gordon",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2021-10-24",
    "categories": [],
    "contents": "\r\nThis is an exploration into this non-parametric test insofar as I can manage.\r\nThe document details the following: Some information about non parametric tests and What is the wilcoxin-mann whitney test The forumla and an intuition for how the test works Some considerations when using the test A stress test for when the test is no longer reliable\r\nSome information about Non-Parametric Test At some point you realize that the initial statistical golems (or tests) that you are introduced initially have quite a bit of contraints on them. It is not obvious that the contrainsts are just that, constraints. So you eventually realize that you can remove them, although it’s another skill to manipulate the tests to have the properties you desire. That’s what a statistician can do, myself still being a wanna be hack that occasioanlly gets glossy eyed when I come across these things.\r\nIn any case, the definitions or rather guiding requirements for a non-parametric test being that it doesn’t satisfy some requirement in a list that would qualify for a parametric test turns out to be an unreliable way to classify these golems. The working definitions that I have choosen (for now) is that non-parametric tests use distributions that can’t be described by a finite number of parameters when making inferences about the population which is to say these use golems that are infinite dimensional (all of non para larry). The counter part, parametric inference assumes some information about the population probability density function, such that it belongs to a particular family of distributions that is defined by a finite number of parameters (intro to non-para 2009).\r\nThe wilcoxin-mann whiteny test (WMWT) does not use any priori information about the population density and falls into the category as non-parametric.\r\nsome intution about how it works\r\nThere are two names written into the title being wilcoxin and mann-whiteny. It seems like developed tests that are equivalent to each other with one being contained in the other and the results the same. Wilcoxin derived a statistic that will be referred to as W being \\[\\sum c_i R_i\\] which is referrerd to as a linear rank statistic. The ranks given by \\[R_i\\] are added together and weighted by \\[c_i\\] in some fashion the satistician deems useful. In our case for the WMW all of the \\[c_i\\] are values of one, and we operate with just the ranks.\r\nThe mann whiteny version of events i found to be the more intuitive; this looks like \\[\\sum_{i=1}^n \\sum_{j=1}^m \\phi (x_i,y_j) \\] where \\[\\phi (x_i,y_j)\\] is defined as follows: \\[ \\begin{cases} \r\n      1 & x_i < y_j \\\\\r\n      0.5 & x_i = y_j \\\\\r\n      0 & x_i > y_j \r\n   \\end{cases}\r\n\\] Now what this does is that it takes every data point from the first group and makes a comparison to every data point from the second group, producing a score according to the rules defined above. This is literally as though if you were to manually compare every data point from each group to another every time asking if its greater than, equal or less than in order to get a sense of where the point is to the other group, then keep track of this “distance” by using a simple count.\r\nThis relates to wilcoxin in that \\[W = U + \\dfrac{n(n+1)}{2} \\].\r\nNow that we have a measure of distance we can compare this to what we might expect if the population density distributions for the two groups were the same. It’s at this point the infernce begins such that we try to connect the sample statitic with what may be happening in the population.\r\nFinally we will now compare this to the situation under the null hypothesis such that there is no difference between the linear rank statistics of the groups (you could have chosen either one. This looks like the familiar set up:\r\n\\[ \\dfrac{W - \\mathop{\\mathbb{E}}(W_o)}{\\mathop{\\mathbb{V}}(W_o)}\\]\r\nwhere \\[\r\nW_o = \\dfrac{n(N+1)}{2}\r\n\\]\r\nand the variance depending on whether there are ties as:\r\n\\[\r\n\\mathop{\\mathbb{V}}(W_o) = \\dfrac{mn(N+1)}{2}\r\n\\]\r\nand if there are ties in the data then\r\n\\[\r\n\\mathop{\\mathbb{V}}(W_o) = \\dfrac{mn}{12} (N+1- \\dfrac{ \\sum_{i=1}^g (t_i-1)t_i(t_i+1)}{N(N-1)})\r\n\\]\r\nSome considerations\r\nSo one of the “assumptions” for the parametric tests is that there is homoscedasticity present across the groups which is to say that the variance of the groups are the same. The purpose of this in the context of the t-sample independet samples test is as follows:\r\nA normal distribution is assigned to each group for which you have to estimate the values of two parameters, being the mean and the variance. This test becomes a test for the means, if the variances are both the same. This test becomes a test for difference in the variances if the means are the same (taken with salt). This test becomes a test if the distributions for the two groups are not the same (unknown whether it’s the mean or the variance) if both of these quantities aren’t the same.\r\nNow a similar thing happens for the non-parametric test but you won’t call this homoscedasitcity per say. But you will require that the shape of the distributions ( which can be described by the variance, skewness, kurtosis) be the same before this becomes a test of whether the location being the medians are the same. This test, does not use the median in it’s calculation but may be equivalent to comparing median although i’m not sure why it can’t be said for the mean as well which you’re requiring the shapes to be different in any case that should apply to all of the location parameters (check).\r\nRank tests does not use all the avaliable information in the sample. (check out some stuff for this)\r\nTalk about the efficiency compared to the students T test under the conditions of the normal distribution being true vs it not being true. Maybe we can throw in the simulation exercise for this as well.\r\ne two-sidedWMWtest is consistent against all alternatives\r\nwith Pr(Xi < Yj) x ý. . not sure what this means\r\nHowever, the WMW\r\ntest can give a signicant result for a test at the  % level\r\nwith much more than  % probability when the population\r\nmedians are identical, but the population variances dier.\r\nLets talk about estimation\r\nUnder the null hypothesis the wilcoxin stat follows a standard normal distribution. There is the normal approximation that can be used if there are no ties in the ranks. Acceptable if \\[min(m,n) \\geq 7\\] You can do the two sided test, the p values or whatever quantiles suite your jazz\r\nYou can also do the permutation somewhat to get the null distribution of\r\n\\[\r\nW_o\r\n\\]\r\nImprovements of the mann-whiteney test\r\ngeneralization exists that can be applied for testing a difference\r\nin location irrespective of a possible dierence in\r\nvariability\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-10-24T18:12:11-04:00",
    "input_file": "wilcoxin-mann-whitney-test.knit.md"
  },
  {
    "path": "posts/welcome/",
    "title": "Multivariate Analysis",
    "description": "This section contains questions that use various multivariate techniques. Each problem explores the assumptions required to use the technique, performs exploratory analysis where possible and in some cases comment on the experimental design when it is available. In cases where the technique is not found to be appropriate the aim will be to suggest alternatives.",
    "author": [
      {
        "name": "Gavin Gordon",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2020-12-16",
    "categories": [],
    "contents": "\r\nPlanned features:\r\nDashboards\r\nNot sure about shiny apps.\r\nSection for monte carlo\r\nSection for designs of experiments\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-10-24T15:51:01-04:00",
    "input_file": "welcome.knit.md"
  }
]
